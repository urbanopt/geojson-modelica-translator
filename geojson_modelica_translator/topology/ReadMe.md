The files in this folder ('Topology') are used to run a topology optimization analysis, leveraging the OpenStudio Analysis Framework, for a district thermal energy system model generated by the GMT.
In its current form, this is for a demonstration, proof-of-concept analysis. The topology optimization problem addressed here is focused on the selection
of a subset of buildings to be connected to the network. Thus far, this has been implemented for only one building's connectivity status, but could easily
be extended to more buildings in the future. Input files are currently configured to be executed for an example project created by the UO-DES commands for
URBANopt-SDK generated inputs.

The use of PSO for the network topology optimization problem for district thermal energy systems has been validated in work documented in Allen et al. (2021).

The objective function considered is the overall source energy consumption for HVAC of the district. The analysis can be run using the folowing steps:

1. Build a Docker container using the Dockerfile in this folder.
2. Within the "worker" that starts, run ". ./set_up_v2.sh" file to install needed packages and configure GitHub repositories. (Confirm that this file has LF line endings.)
3. Create a CSV file with the annual HVAC energy use, at an hourly interval, of the considered building in a state with "independent" (non-DES-tied)
systems. As currently configured, this file should be named "in.csv" and exist in this folder, with columns labeled 'Electricity:Facility [J](TimeStep)' and
'NaturalGas:Facility [J](TimeStep)' corresponding to the overall electricity and natural gas use, respectively, associated with the building's HVAC systems.
(The 'post_processing.py' script in this folder can be modified to accomodate different column heading names, if desired.) To run an example analysis, one can
leave the "in.csv" file in this folder as is.
4. As configured now, the first building listed in the file named "example_project.json" (in the tests/data/management/sdk_project_scraps folder) will have its connectivity status treated as an optimization variable.
This can be modified, if desired, by editing the "create_fmu.py" script in this folder.

The compile_and_simulate.py script is currently configured to run the simulation for one day, for computational tractability--this can be modified in the time duration in the script.

5. Configure a PAT project that runs the "Read FMU Results" measure. This is already configured in the OSAF_analysis_file.json file located in this folder.
This analysis can be executed with a command such as follows:

<path to Ruby exe in PAT> C:\ParametricAnalysisTool-3.2.1\pat\OpenStudio-server\bin\openstudio_meta run_analysis --debug --verbose "<Path to OSAF analysis JSON" "http://127.0.0.1:8080/" -a pso

6. Use the web interface of the OSAF server you have built using the Dockerfile to view results.


The assistance of Brian Ball and Nick Long in configuring an OSAF workflow for this analysis is gratefully acknowledged!
